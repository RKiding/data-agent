"""
å®Œæ•´çš„æ•°æ®ç§‘å­¦åˆ†ææµç¨‹
æ•´åˆæ•°æ®æ¸…æ´—ã€ç‰¹å¾å·¥ç¨‹ã€EDAã€æ¨¡å‹è®­ç»ƒã€å¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import pandas as pd
from typing import Dict, Any, List, Optional
from datetime import datetime
import json

# æ·»åŠ agentsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'agents'))

# å¯¼å…¥æ‰€æœ‰agent
from agents.data_cleaning import run_data_cleaning
from agents.feature_engineering import run_feature_engineering
from agents.eda_agent import run_eda_analysis
from agents.model_training_agent import run_model_training
from agents.visualization_agent import run_visualization, load_analysis_results
from agents.report_generation_agent import run_report_generation, load_all_results, find_visualization_files

class DataSciencePipeline:
    """å®Œæ•´çš„æ•°æ®ç§‘å­¦åˆ†ææµç¨‹ç®¡ç†å™¨"""
    
    def __init__(self, data_path: str, output_dir: str = "output"):
        self.data_path = data_path
        self.output_dir = output_dir
        self.results = {}
        self.pipeline_config = {
            "enable_manual_review": False,
            "enable_rag": False,
            "target_variable": None,
            "problem_type": None,
            "report_format": "markdown"  # æ–°å¢ï¼šæŠ¥å‘Šæ ¼å¼
        }
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"ğŸš€ åˆå§‹åŒ–æ•°æ®ç§‘å­¦æµç¨‹")
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {self.data_path}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def configure_pipeline(self, **kwargs):
        """é…ç½®æµç¨‹å‚æ•°"""
        self.pipeline_config.update(kwargs)
        print(f"âš™ï¸ æµç¨‹é…ç½®æ›´æ–°: {kwargs}")
        if "report_format" in kwargs:
            print(f"ğŸ“„ æŠ¥å‘Šè¾“å‡ºæ ¼å¼: {kwargs['report_format']}")
    
    def run_data_cleaning(self, user_instructions: str = "è¯·æ¸…æ´—è¿™ä»½æ•°æ®ï¼Œå¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼å’Œé‡å¤æ•°æ®") -> str:
        """æ­¥éª¤1: æ•°æ®æ¸…æ´—"""
        print("\n" + "="*50)
        print("æ­¥éª¤ 1: æ•°æ®æ¸…æ´—")
        print("="*50)
        
        try:
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®ç°æ•°æ®æ¸…æ´—çš„è°ƒç”¨é€»è¾‘
            # ç”±äºåŸå§‹çš„data_cleaning.pyç»“æ„ï¼Œæˆ‘ä»¬éœ€è¦é€‚é…
            print("æ•°æ®æ¸…æ´—åŠŸèƒ½éœ€è¦ä»agents/data_cleaning.pyä¸­å•ç‹¬å®ç°")
            print("æš‚æ—¶è·³è¿‡æ•°æ®æ¸…æ´—æ­¥éª¤ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            
            # å¤åˆ¶åŸå§‹æ•°æ®ä½œä¸ºæ¸…æ´—åçš„æ•°æ®
            cleaned_data_path = os.path.join(self.output_dir, "cleaned_data.csv")
            data = pd.read_csv(self.data_path)
            data.to_csv(cleaned_data_path, index=False)
            
            self.results["data_cleaning"] = {
                "input_path": self.data_path,
                "output_path": cleaned_data_path,
                "status": "completed"
            }
            
            return cleaned_data_path
            
        except Exception as e:
            print(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            self.results["data_cleaning"] = {"status": "failed", "error": str(e)}
            return self.data_path  # è¿”å›åŸå§‹æ•°æ®è·¯å¾„
    
    def run_feature_engineering(self, data_path: str, user_instructions: str = "è¯·å¯¹è¿™ä»½é‡‘èæ•°æ®åšç‰¹å¾å·¥ç¨‹") -> str:
        """æ­¥éª¤2: ç‰¹å¾å·¥ç¨‹"""
        print("\n" + "="*50) 
        print("æ­¥éª¤ 2: ç‰¹å¾å·¥ç¨‹")
        print("="*50)
        
        try:
            # ä½¿ç”¨agents.feature_engineeringæ¨¡å—
            engineered_data_path = run_feature_engineering(
                data_path=data_path,
                input_text=user_instructions,
                target_variable=self.pipeline_config.get("target_variable"),
                enable_manual_review=self.pipeline_config["enable_manual_review"],
                enable_rag=self.pipeline_config["enable_rag"]
            )
            
            if engineered_data_path and os.path.exists(engineered_data_path):
                # è¯»å–æ•°æ®ä»¥è·å–å½¢çŠ¶ä¿¡æ¯
                original_data = pd.read_csv(data_path)
                engineered_data = pd.read_csv(engineered_data_path)
                
                self.results["feature_engineering"] = {
                    "input_path": data_path,
                    "output_path": engineered_data_path,
                    "input_shape": original_data.shape,
                    "output_shape": engineered_data.shape,
                    "status": "completed"
                }
                
                return engineered_data_path
            else:
                raise Exception("ç‰¹å¾å·¥ç¨‹å¤±è´¥ï¼šæœªç”Ÿæˆæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
                
        except Exception as e:
            print(f"ç‰¹å¾å·¥ç¨‹å¤±è´¥: {str(e)}")
            self.results["feature_engineering"] = {"status": "failed", "error": str(e)}
            return data_path  # è¿”å›åŸå§‹æ•°æ®è·¯å¾„ä½œä¸ºfallback
    
    def run_eda(self, data_path: str, user_instructions: str = "è¯·å¯¹è¿™ä»½æœŸè´§æ•°æ®è¿›è¡Œå…¨é¢çš„æ¢ç´¢æ€§æ•°æ®åˆ†æ") -> Dict[str, Any]:
        """æ­¥éª¤3: æ¢ç´¢æ€§æ•°æ®åˆ†æ"""
        print("\n" + "="*50)
        print("æ­¥éª¤ 3: æ¢ç´¢æ€§æ•°æ®åˆ†æ (EDA)")
        print("="*50)
        
        try:
            eda_results = run_eda_analysis(
                data_path=data_path,
                input_text=user_instructions,
                target_variable=self.pipeline_config.get("target_variable"),
                enable_manual_review=self.pipeline_config["enable_manual_review"],
                enable_rag=self.pipeline_config["enable_rag"]
            )
            
            if eda_results:
                self.results["eda"] = {
                    "status": "completed",
                    "results": eda_results,
                    "output_path": "output/eda_results.pkl"
                }
                return eda_results
            else:
                raise Exception("EDAåˆ†æå¤±è´¥")
                
        except Exception as e:
            print(f"EDAåˆ†æå¤±è´¥: {str(e)}")
            self.results["eda"] = {"status": "failed", "error": str(e)}
            return None
    
    def run_model_training(self, data_path: str, user_instructions: str = "è¯·å¯¹è¿™ä»½æœŸè´§æ•°æ®è¿›è¡Œæœºå™¨å­¦ä¹ å»ºæ¨¡") -> Dict[str, Any]:
        """æ­¥éª¤4: æ¨¡å‹è®­ç»ƒ"""
        print("\n" + "="*50)
        print("æ­¥éª¤ 4: æ¨¡å‹è®­ç»ƒ")
        print("="*50)
        
        try:
            model_results = run_model_training(
                data_path=data_path,
                input_text=user_instructions,
                target_variable=self.pipeline_config.get("target_variable"),
                problem_type=self.pipeline_config.get("problem_type"),
                enable_manual_review=self.pipeline_config["enable_manual_review"],
                enable_rag=self.pipeline_config["enable_rag"]
            )
            
            if model_results:
                self.results["model_training"] = {
                    "status": "completed",
                    "results": model_results,
                    "output_path": "output/model_results.pkl",
                    "best_model_path": "output/best_model.pkl"
                }
                return model_results
            else:
                raise Exception("æ¨¡å‹è®­ç»ƒå¤±è´¥")
                
        except Exception as e:
            print(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")
            self.results["model_training"] = {"status": "failed", "error": str(e)}
            return None
    
    def run_visualization(self, data_path: str, user_instructions: str = "è¯·ä¸ºè¿™ä»½æœŸè´§æ•°æ®ç”Ÿæˆå…¨é¢çš„å¯è§†åŒ–å›¾è¡¨") -> List[str]:
        """æ­¥éª¤5: æ•°æ®å¯è§†åŒ–"""
        print("\n" + "="*50)
        print("æ­¥éª¤ 5: æ•°æ®å¯è§†åŒ–")
        print("="*50)
        
        try:
            # åŠ è½½ä¹‹å‰çš„åˆ†æç»“æœ
            analysis_results = load_analysis_results(
                eda_results_path="output/eda_results.pkl",
                model_results_path="output/model_results.pkl"
            )
            
            generated_plots = run_visualization(
                data_path=data_path,
                input_text=user_instructions,
                analysis_results=analysis_results,
                enable_manual_review=self.pipeline_config["enable_manual_review"],
                enable_rag=self.pipeline_config["enable_rag"]
            )
            
            if generated_plots:
                self.results["visualization"] = {
                    "status": "completed",
                    "plots": generated_plots,
                    "plot_count": len(generated_plots)
                }
                return generated_plots
            else:
                print("å¯è§†åŒ–ç”Ÿæˆå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
                self.results["visualization"] = {"status": "failed", "plots": []}
                return []
                
        except Exception as e:
            print(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {str(e)}")
            self.results["visualization"] = {"status": "failed", "error": str(e), "plots": []}
            return []
    
    def run_report_generation(self, data_path: str) -> str:
        """æ­¥éª¤6: æŠ¥å‘Šç”Ÿæˆï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
        print("\n" + "="*50)
        print("æ­¥éª¤ 6: æŠ¥å‘Šç”Ÿæˆ")
        print("="*50)
        
        report_format = self.pipeline_config.get("report_format", "markdown")
        print(f"ğŸ“„ æŠ¥å‘Šæ ¼å¼: {report_format}")
        
        try:
            # åŠ è½½æ‰€æœ‰åˆ†æç»“æœ
            eda_results, model_results = load_all_results(
                eda_results_path="output/eda_results.pkl",
                model_results_path="output/model_results.pkl"
            )
            
            # æŸ¥æ‰¾å¯è§†åŒ–æ–‡ä»¶
            visualizations = find_visualization_files("visualizations")
            
            report_path = run_report_generation(
                data_path=data_path,
                eda_results=eda_results,
                model_results=model_results,
                visualizations=visualizations,
                output_format=report_format,  # æ–°å¢å‚æ•°
                enable_rag=self.pipeline_config["enable_rag"]
            )
            
            if report_path:
                self.results["report_generation"] = {
                    "status": "completed",
                    "report_path": report_path,
                    "format": report_format
                }
                return report_path
            else:
                raise Exception("æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                
        except Exception as e:
            print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
            self.results["report_generation"] = {"status": "failed", "error": str(e)}
            return None
    
    def run_complete_pipeline(self, custom_instructions: Dict[str, str] = None) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„æ•°æ®ç§‘å­¦æµç¨‹"""
        print("\n" + "="*80)
        print("å¼€å§‹æ‰§è¡Œå®Œæ•´çš„æ•°æ®ç§‘å­¦åˆ†ææµç¨‹")
        print("="*80)
        
        start_time = datetime.now()
        
        # é»˜è®¤æŒ‡ä»¤
        default_instructions = {
            "data_cleaning": "è¯·æ¸…æ´—è¿™ä»½æ•°æ®ï¼Œå¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼å’Œé‡å¤æ•°æ®",
            "feature_engineering": "è¯·å¯¹è¿™ä»½é‡‘èæ•°æ®åšç‰¹å¾å·¥ç¨‹ï¼Œé‡ç‚¹å…³æ³¨ä»·æ ¼ã€æˆäº¤é‡å’ŒæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾",
            "eda": "è¯·å¯¹è¿™ä»½æœŸè´§æ•°æ®è¿›è¡Œå…¨é¢çš„æ¢ç´¢æ€§æ•°æ®åˆ†æï¼Œé‡ç‚¹åˆ†æä»·æ ¼èµ°åŠ¿ã€æˆäº¤é‡æ¨¡å¼å’Œå„ç‰¹å¾ä¹‹é—´çš„å…³ç³»",
            "model_training": "è¯·å¯¹è¿™ä»½æœŸè´§æ•°æ®è¿›è¡Œæœºå™¨å­¦ä¹ å»ºæ¨¡ï¼Œé¢„æµ‹ä»·æ ¼è¶‹åŠ¿æˆ–æ”¶ç›Šç‡",
            "visualization": "è¯·ä¸ºè¿™ä»½æœŸè´§æ•°æ®ç”Ÿæˆå…¨é¢çš„å¯è§†åŒ–å›¾è¡¨ï¼ŒåŒ…æ‹¬ä»·æ ¼èµ°åŠ¿ã€ç‰¹å¾åˆ†å¸ƒã€ç›¸å…³æ€§åˆ†æå’Œæ¨¡å‹ç»“æœå¯è§†åŒ–",
        }
        
        # åˆå¹¶è‡ªå®šä¹‰æŒ‡ä»¤
        if custom_instructions:
            default_instructions.update(custom_instructions)
        
        current_data_path = self.data_path
        
        # æ­¥éª¤1: æ•°æ®æ¸…æ´—
        current_data_path = self.run_data_cleaning(default_instructions["data_cleaning"])
        
        # æ­¥éª¤2: ç‰¹å¾å·¥ç¨‹
        current_data_path = self.run_feature_engineering(current_data_path, default_instructions["feature_engineering"])
        
        # æ­¥éª¤3: EDA
        eda_results = self.run_eda(current_data_path, default_instructions["eda"])
        
        # æ­¥éª¤4: æ¨¡å‹è®­ç»ƒ
        model_results = self.run_model_training(current_data_path, default_instructions["model_training"])
        
        # æ­¥éª¤5: å¯è§†åŒ–
        visualizations = self.run_visualization(current_data_path, default_instructions["visualization"])
        
        # æ­¥éª¤6: æŠ¥å‘Šç”Ÿæˆ
        report_path = self.run_report_generation(current_data_path)
        
        # è®¡ç®—æ€»è€—æ—¶
        end_time = datetime.now()
        total_time = end_time - start_time
        
        # æ±‡æ€»ç»“æœ
        summary = {
            "pipeline_config": self.pipeline_config,
            "execution_time": str(total_time),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "results": self.results,
            "final_data_path": current_data_path,
            "report_path": report_path,
            "success_rate": sum(1 for r in self.results.values() if r.get("status") == "completed") / len(self.results)
        }
        
        # ä¿å­˜æµç¨‹æ‘˜è¦
        summary_path = os.path.join(self.output_dir, "pipeline_summary.json")
        with open(summary_path, "w", encoding="utf-8") as f:
            # å°†ä¸èƒ½JSONåºåˆ—åŒ–çš„å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            json_summary = self._make_json_serializable(summary)
            json.dump(json_summary, f, ensure_ascii=False, indent=2)
        
        print("\n" + "="*80)
        print("æ•°æ®ç§‘å­¦åˆ†ææµç¨‹æ‰§è¡Œå®Œæˆ")
        print("="*80)
        print(f"æ€»è€—æ—¶: {total_time}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1%}")
        print(f"æœ€ç»ˆæ•°æ®æ–‡ä»¶: {current_data_path}")
        print(f"åˆ†ææŠ¥å‘Š: {report_path}")
        print(f"æµç¨‹æ‘˜è¦: {summary_path}")
        
        return summary
    
    def _make_json_serializable(self, obj):
        """ä½¿å¯¹è±¡å¯ä»¥è¢«JSONåºåˆ—åŒ–"""
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif hasattr(obj, 'isoformat'):  # datetimeå¯¹è±¡
            return obj.isoformat()
        elif hasattr(obj, '__dict__'):  # å…¶ä»–å¯¹è±¡
            return str(obj)
        else:
            return obj

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´çš„æ•°æ®ç§‘å­¦æµç¨‹"""
    
    # é…ç½®å‚æ•°
    data_path = "/Users/runkeruan/Desktop/RBM/data-agent-for-futures/output/cleaned_B.csv"
    target_variable = None  # æ ¹æ®å®é™…æƒ…å†µè®¾ç½®ï¼Œä¾‹å¦‚ "close_price" æˆ– "return"
    
    print("\n" + "="*80)
    print("ğŸš€ æ•°æ®ç§‘å­¦æ™ºèƒ½åˆ†æç³»ç»Ÿ")
    print("="*80)
    print("âœ¨ æ–°åŠŸèƒ½:")
    print("  - ğŸ”„ è¿›åº¦æ¡æ˜¾ç¤º")
    print("  - ğŸ§ª å°æ ·æœ¬æµ‹è¯•æ¨¡å¼")
    print("  - ğŸ“„ å¤šç§æŠ¥å‘Šæ ¼å¼æ”¯æŒ (markdown, html, json, pdf)")
    print("  - ğŸ›¡ï¸ æ”¹è¿›çš„é”™è¯¯å¤„ç†")
    print("="*80)
    
    # åˆå§‹åŒ–æµç¨‹
    pipeline = DataSciencePipeline(data_path)
    
    # é…ç½®æµç¨‹å‚æ•°
    pipeline.configure_pipeline(
        enable_manual_review=False,  # æ˜¯å¦å¯ç”¨äººå·¥å®¡æ ¸
        enable_rag=False,           # æ˜¯å¦å¯ç”¨RAG
        target_variable=target_variable,
        problem_type=None,          # è®©ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹
        report_format="markdown"    # å¯é€‰: markdown, html, json, pdf
    )
    
    # è‡ªå®šä¹‰æŒ‡ä»¤ï¼ˆå¯é€‰ï¼‰
    custom_instructions = {
        "feature_engineering": "è¯·å¯¹è¿™ä»½æœŸè´§æ•°æ®åšç‰¹å¾å·¥ç¨‹ï¼Œé‡ç‚¹åˆ›å»ºæŠ€æœ¯åˆ†ææŒ‡æ ‡ã€æ»‘åŠ¨å¹³å‡çº¿ã€ä»·æ ¼å˜åŒ–ç‡ç­‰é‡‘èç‰¹å¾",
        "eda": "è¯·å¯¹è¿™ä»½æœŸè´§æ•°æ®è¿›è¡Œæ·±å…¥çš„æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ŒåŒ…æ‹¬ä»·æ ¼è¶‹åŠ¿åˆ†æã€äº¤æ˜“é‡åˆ†æã€æ³¢åŠ¨æ€§åˆ†æå’Œå­£èŠ‚æ€§æ¨¡å¼",
        "model_training": "è¯·æ„å»ºå¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹æ¥é¢„æµ‹æœŸè´§ä»·æ ¼è¶‹åŠ¿ï¼ŒåŒ…æ‹¬å›å½’æ¨¡å‹å’Œåˆ†ç±»æ¨¡å‹ï¼Œå¹¶è¿›è¡Œæ¨¡å‹å¯¹æ¯”",
        "visualization": "è¯·ç”Ÿæˆä¸“ä¸šçš„é‡‘èæ•°æ®å¯è§†åŒ–å›¾è¡¨ï¼ŒåŒ…æ‹¬Kçº¿å›¾ã€æŠ€æœ¯æŒ‡æ ‡å›¾ã€ç›¸å…³æ€§çƒ­åŠ›å›¾å’Œæ¨¡å‹æ€§èƒ½å›¾è¡¨"
    }
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    results = pipeline.run_complete_pipeline(custom_instructions)    
    print(f"\nğŸ‰ æµç¨‹æ‰§è¡Œå®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸç‡: {results.get('success_rate', 0):.1%}")
    print(f"â±ï¸ æ€»è€—æ—¶: {results.get('execution_time', 'N/A')}")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: {results.get('report_path', 'output/comprehensive_analysis_report.md')}")
    
    # æ˜¾ç¤ºæ”¯æŒçš„æŠ¥å‘Šæ ¼å¼
    print(f"\nğŸ“„ æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼:")
    print(f"  - markdown: è½»é‡çº§æ ‡è®°è¯­è¨€æ ¼å¼")
    print(f"  - html: ç½‘é¡µæ ¼å¼ï¼Œå¯åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹")
    print(f"  - json: ç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼Œä¾¿äºç¨‹åºå¤„ç†")
    print(f"  - pdf: ä¾¿æºå¼æ–‡æ¡£æ ¼å¼ï¼ˆéœ€è¦é¢å¤–ä¾èµ–ï¼‰")
    print(f"\nğŸ’¡ æç¤º: å¯ä»¥é€šè¿‡ä¿®æ”¹ report_format å‚æ•°æ¥é€‰æ‹©ä¸åŒçš„è¾“å‡ºæ ¼å¼")

if __name__ == "__main__":
    main()