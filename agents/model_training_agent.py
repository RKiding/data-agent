import os
import pandas as pd
from typing import Optional, List, TypedDict, Any, Dict
from tqdm import tqdm
import time

from pydantic import BaseModel, Field
from langgraph.graph import Graph
from langchain.chat_models import init_chat_model

from prompt import (
    model_training_recommend_steps_prompt,
    model_training_prompt,
    model_training_code_fix_prompt,
)
from utils.dataframe import get_dataframe_summary
from utils.regex import relocate_imports_inside_function
from utils.rag_tool import rag_retrieve_agentic
from utils.llm_utils import get_default_llm
from parsers import PythonOutputParser

from dotenv import load_dotenv

load_dotenv()

# ä½¿ç”¨ç»Ÿä¸€çš„LLMåˆå§‹åŒ–
llm = get_default_llm()

class Router(BaseModel):
    """ a class for model training python code generation """
    output: Optional[str] = Field(
        description="The output text generated by the model."
    )
    steps: Optional[List[str]] = Field(
        description="A list of steps to be followed for model training."
    )

llm_router = llm.with_structured_output(Router) if llm else None

class ModelTrainingState(TypedDict):
    data: pd.DataFrame
    data_summary: str
    recommended_steps: str
    training_code: str
    model_results: Optional[Dict[str, Any]]
    error: Optional[str]
    retry_count: int
    target_variable: str
    problem_type: str  # 'classification', 'regression', 'clustering'
    sample_test_passed: bool  # æ–°å¢ï¼šå°æ ·æœ¬æµ‹è¯•æ˜¯å¦é€šè¿‡

def determine_problem_type(data: pd.DataFrame, target_variable: str) -> str:
    """æ ¹æ®ç›®æ ‡å˜é‡ç¡®å®šé—®é¢˜ç±»å‹"""
    if target_variable and target_variable in data.columns:
        target_series = data[target_variable]
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å€¼å‹
        if pd.api.types.is_numeric_dtype(target_series):
            unique_values = target_series.nunique()
            # å¦‚æœå”¯ä¸€å€¼å¾ˆå°‘ï¼Œå¯èƒ½æ˜¯åˆ†ç±»é—®é¢˜
            if unique_values <= 10:
                return "classification"
            else:
                return "regression"
        else:
            return "classification"
    else:
        return "regression"  # é»˜è®¤ä¸ºå›å½’

def get_data_summary(state: ModelTrainingState) -> ModelTrainingState:
    data_summary = get_dataframe_summary(state["data"])
    state["data_summary"] = "\n\n".join(data_summary)
    
    # è‡ªåŠ¨ç¡®å®šé—®é¢˜ç±»å‹
    if not state.get("problem_type"):
        state["problem_type"] = determine_problem_type(state["data"], state.get("target_variable", ""))
    
    # åˆå§‹åŒ–å°æ ·æœ¬æµ‹è¯•çŠ¶æ€
    state["sample_test_passed"] = False
    
    return state

def recommend_training_steps(state: ModelTrainingState, input: str, enable_rag: bool = True) -> ModelTrainingState:
    if not llm_router:
        state["error"] = "LLMæœªæ­£ç¡®åˆå§‹åŒ–"
        return state
        
    print("ğŸ” æ¨èè®­ç»ƒæ­¥éª¤...")
    rag_context = ""
    if enable_rag:
        rag_context = rag_retrieve_agentic(
            context=state["data_summary"],
            task=input
        )
    prompt = model_training_recommend_steps_prompt.format(
        user_instructions=input,
        target_variable=state.get("target_variable", ""),
        problem_type=state.get("problem_type", "regression"),
        recommended_steps=None,
        all_datasets_summary=state["data_summary"] + ("\n\n" + rag_context if rag_context else "")
    )
    output = llm_router.invoke(prompt)
    state["recommended_steps"] = "\n\n".join(output.steps) if output.steps else ""
    return state

def generate_training_code(state: ModelTrainingState) -> ModelTrainingState:
    if not llm:
        state["error"] = "LLMæœªæ­£ç¡®åˆå§‹åŒ–"
        return state
        
    print("\n=== å¼€å§‹ç”Ÿæˆæ¨¡å‹è®­ç»ƒä»£ç  ===")
    print("åŸºäºä»¥ä¸‹æ­¥éª¤ç”Ÿæˆä»£ç :")
    print(state["recommended_steps"])
    print(f"é—®é¢˜ç±»å‹: {state.get('problem_type', 'regression')}")
    print(f"ç›®æ ‡å˜é‡: {state.get('target_variable', 'None')}")
    
    # æ·»åŠ å°æ ·æœ¬æµ‹è¯•çš„æç¤º
    enhanced_prompt = model_training_prompt.format(
        function_name="train_models",
        recommended_steps=state["recommended_steps"],
        target_variable=state.get("target_variable", ""),
        problem_type=state.get("problem_type", "regression"),
        all_datasets_summary=state["data_summary"]
    ) + """
    
    IMPORTANT: The function should support a 'sample_size' parameter for testing with small samples first.
    If sample_size is provided and > 0, use only that many rows for training.
    Also add progress tracking with tqdm for long-running operations.
    """
    
    with tqdm(total=1, desc="ğŸ¤– ç”Ÿæˆè®­ç»ƒä»£ç ") as pbar:
        output = llm.invoke(enhanced_prompt)
        pbar.update(1)
    
    training_code = PythonOutputParser().parse(output.content)
    
    if "def train_models" not in training_code:
        print("è­¦å‘Š: ç”Ÿæˆçš„ä»£ç ä¸­æœªæ‰¾åˆ° train_models å‡½æ•°å®šä¹‰")
        state["error"] = "ç”Ÿæˆçš„ä»£ç ä¸­ç¼ºå°‘ train_models å‡½æ•°å®šä¹‰"
    else:
        state["training_code"] = training_code
        print("\nç”Ÿæˆçš„ä»£ç :")
        print(state["training_code"])
        os.makedirs("tmp", exist_ok=True)
        with open("tmp/train_models.py", "w") as f:
            f.write(state["training_code"])
    return state

def run_sample_test(state: ModelTrainingState) -> ModelTrainingState:
    """è¿è¡Œå°æ ·æœ¬æµ‹è¯•"""
    print("\n=== å¼€å§‹å°æ ·æœ¬æµ‹è¯• (100æ¡è®°å½•) ===")
    try:
        local_namespace = {}
        exec(state["training_code"], globals(), local_namespace)
        if 'train_models' not in local_namespace:
            raise NameError("æœªèƒ½æˆåŠŸå®šä¹‰ train_models å‡½æ•°")
        train_models = local_namespace['train_models']
        
        # ä½¿ç”¨å°æ ·æœ¬æµ‹è¯•
        sample_size = min(100, len(state["data"]))
        print(f"ä½¿ç”¨ {sample_size} æ¡è®°å½•è¿›è¡Œæµ‹è¯•...")
        
        with tqdm(total=1, desc="ğŸ§ª å°æ ·æœ¬æµ‹è¯•") as pbar:
            # å°è¯•è°ƒç”¨å‡½æ•°ï¼ˆå¯èƒ½éœ€è¦ä¿®æ”¹å‡½æ•°ç­¾åæ”¯æŒsample_sizeå‚æ•°ï¼‰
            try:
                test_results = train_models(state["data"], state.get("target_variable"), sample_size=sample_size)
            except TypeError:
                # å¦‚æœä¸æ”¯æŒsample_sizeå‚æ•°ï¼Œå°±ç”¨å‰100è¡Œ
                test_data = state["data"].head(sample_size)
                test_results = train_models(test_data, state.get("target_variable"))
            pbar.update(1)
        
        if test_results and isinstance(test_results, dict):
            state["sample_test_passed"] = True
            print("âœ… å°æ ·æœ¬æµ‹è¯•é€šè¿‡ï¼")
            print("æµ‹è¯•ç»“æœåŒ…å«ä»¥ä¸‹ç»„ä»¶:")
            for key in test_results.keys():
                print(f"  - {key}")
        else:
            raise Exception("å°æ ·æœ¬æµ‹è¯•è¿”å›ç»“æœæ— æ•ˆ")
            
    except Exception as e:
        state["error"] = f"å°æ ·æœ¬æµ‹è¯•å¤±è´¥: {str(e)}"
        print(f"âŒ å°æ ·æœ¬æµ‹è¯•å¤±è´¥: {state['error']}")
        print("è®­ç»ƒä»£ç :")
        print(state["training_code"])
        
    return state

def execute_training(state: ModelTrainingState) -> ModelTrainingState:
    """æ‰§è¡Œå®Œæ•´æ¨¡å‹è®­ç»ƒ"""
    if not state.get("sample_test_passed", False):
        print("âš ï¸ è·³è¿‡å®Œæ•´è®­ç»ƒï¼šå°æ ·æœ¬æµ‹è¯•æœªé€šè¿‡")
        return state
        
    print("\n=== å¼€å§‹æ‰§è¡Œå®Œæ•´æ¨¡å‹è®­ç»ƒ ===")
    try:
        local_namespace = {}
        exec(state["training_code"], globals(), local_namespace)
        if 'train_models' not in local_namespace:
            raise NameError("æœªèƒ½æˆåŠŸå®šä¹‰ train_models å‡½æ•°")
        train_models = local_namespace['train_models']
        
        print(f"ä½¿ç”¨å…¨éƒ¨ {len(state['data'])} æ¡è®°å½•è¿›è¡Œè®­ç»ƒ...")
        
        # æ‰§è¡Œå®Œæ•´æ¨¡å‹è®­ç»ƒï¼Œå¸¦è¿›åº¦æ¡
        with tqdm(total=1, desc="ğŸš€ å®Œæ•´æ¨¡å‹è®­ç»ƒ") as pbar:
            state["model_results"] = train_models(state["data"], state.get("target_variable"))
            pbar.update(1)
            
        state["error"] = None
        
        print("âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆ")
        print("è®­ç»ƒç»“æœåŒ…å«ä»¥ä¸‹ç»„ä»¶:")
        for key in state["model_results"].keys():
            print(f"  - {key}")
            
        # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹ä¿¡æ¯
        if "best_model" in state["model_results"]:
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {type(state['model_results']['best_model']).__name__}")
        if "model_scores" in state["model_results"]:
            print("\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
            for model_name, score in state["model_results"]["model_scores"].items():
                print(f"  {model_name}: {score:.4f}")
                
    except Exception as e:
        state["error"] = str(e)
        print(f"âŒ æ¨¡å‹è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {state['error']}")
        print("è®­ç»ƒä»£ç :")
        print(state["training_code"])
        
    return state

def handle_error(state: ModelTrainingState, enable_rag: bool = True) -> ModelTrainingState:
    if not llm:
        state["error"] = "LLMæœªæ­£ç¡®åˆå§‹åŒ–"
        return state
        
    print(f"\n=== å¤„ç†é”™è¯¯ (ç¬¬ {state['retry_count'] + 1} æ¬¡é‡è¯•) ===")
    if state["error"] and state["retry_count"] < 3:
        print(f"å½“å‰é”™è¯¯: {state['error']}")
        rag_context = ""
        if enable_rag:
            rag_context = rag_retrieve_agentic(
                context=state["training_code"] + "\n" + (state["error"] or ""),
                task="ä¿®å¤æ¨¡å‹è®­ç»ƒä»£ç "
            )
        prompt = model_training_code_fix_prompt.format(
            function_name="train_models",
            code_snippet=state["training_code"],
            error=state["error"] + ("\n\n" + rag_context if rag_context else "")
        )
        output = llm.invoke(prompt)
        state["training_code"] = relocate_imports_inside_function(
            PythonOutputParser().parse(output.content)
        )
        print("\nä¿®å¤åçš„ä»£ç :")
        print(state["training_code"])
        os.makedirs("tmp", exist_ok=True)
        with open("tmp/train_models.py", "w") as f:
            f.write(state["training_code"])
        state["retry_count"] += 1
        return state
    print("è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æˆ–æ— é”™è¯¯éœ€è¦å¤„ç†")
    return state

def manual_review(state: ModelTrainingState, user_instructions: str, enable_rag: bool = True) -> ModelTrainingState:
    if not llm_router:
        state["error"] = "LLMæœªæ­£ç¡®åˆå§‹åŒ–"
        return state
        
    print("\n=== äººå·¥å®¡æ ¸æ¨èçš„è®­ç»ƒæ­¥éª¤ ===")
    print("æ¨èçš„è®­ç»ƒæ­¥éª¤ï¼š")
    print(state["recommended_steps"])
    print(f"æ£€æµ‹åˆ°çš„é—®é¢˜ç±»å‹: {state.get('problem_type', 'regression')}")
    print(f"ç›®æ ‡å˜é‡: {state.get('target_variable', 'None')}")
    
    while True:
        user_input = input("æ˜¯å¦æ¥å—æ¨èçš„è®­ç»ƒæ­¥éª¤ï¼Ÿ(y/n)ï¼š").strip().lower()
        if user_input in ("y", "n"):
            break
        print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 'y' æˆ– 'n'ã€‚")
    if user_input == "n":
        while True:
            feedback = input("è¯·ç®€è¦è¯´æ˜ä½ å¯¹æ¨èæ­¥éª¤çš„ä¸æ»¡æˆ–å¸Œæœ›æ”¹è¿›çš„åœ°æ–¹ï¼š\n")
            rag_context = ""
            if enable_rag:
                rag_context = rag_retrieve_agentic(
                    context=state["data_summary"] + "\nç”¨æˆ·åé¦ˆ: " + feedback,
                    task=user_instructions
                )
            prompt = model_training_recommend_steps_prompt.format(
                user_instructions=feedback,
                target_variable=state.get("target_variable", ""),
                problem_type=state.get("problem_type", "regression"),
                recommended_steps=state["recommended_steps"],
                all_datasets_summary=state["data_summary"] + ("\n\n" + rag_context if rag_context else "")
            )
            output = llm_router.invoke(prompt)
            state["recommended_steps"] = "\n\n".join(output.steps) if output.steps else ""
            print("æ ¹æ®åé¦ˆç”Ÿæˆçš„æ–°è®­ç»ƒæ­¥éª¤ï¼š")
            print(state["recommended_steps"])
            while True:
                user_input = input("æ˜¯å¦æ¥å—æ¨èçš„è®­ç»ƒæ­¥éª¤ï¼Ÿ(y/n)ï¼š").strip().lower()
                if user_input in ("y", "n"):
                    break
                print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 'y' æˆ– 'n'ã€‚")
            if user_input == "y":
                break
    return state

def build_training_graph(user_instructions: str, enable_manual_review: bool = False, enable_rag: bool = True) -> Graph:
    workflow = Graph()
    workflow.add_node("get_summary", get_data_summary)
    workflow.add_node("recommend_steps", lambda state: recommend_training_steps(state, user_instructions, enable_rag))
    if enable_manual_review:
        workflow.add_node("manual_review", lambda state: manual_review(state, user_instructions, enable_rag))
    workflow.add_node("generate_code", generate_training_code)
    workflow.add_node("run_sample_test", run_sample_test)
    workflow.add_node("execute_training", execute_training)
    workflow.add_node("handle_error", lambda state: handle_error(state, enable_rag))
    workflow.add_node("end", lambda x: x)

    workflow.add_edge("get_summary", "recommend_steps")
    if enable_manual_review:
        workflow.add_edge("recommend_steps", "manual_review")
        workflow.add_edge("manual_review", "generate_code")
    else:
        workflow.add_edge("recommend_steps", "generate_code")
    workflow.add_edge("generate_code", "run_sample_test")
    
    # å¦‚æœå°æ ·æœ¬æµ‹è¯•é€šè¿‡ï¼Œç»§ç»­å®Œæ•´è®­ç»ƒï¼›å¦‚æœå¤±è´¥ï¼Œè¿›å…¥é”™è¯¯å¤„ç†
    workflow.add_conditional_edges(
        "run_sample_test",
        lambda x: x["error"] is not None,
        {
            True: "handle_error",
            False: "execute_training"
        }
    )
    
    workflow.add_conditional_edges(
        "execute_training",
        lambda x: x["error"] is not None and x["retry_count"] < 5,
        {
            True: "handle_error",
            False: "end"
        }
    )
    workflow.add_edge("handle_error", "run_sample_test")  # é‡è¯•æ—¶é‡æ–°å¼€å§‹å°æ ·æœ¬æµ‹è¯•
    workflow.set_entry_point("get_summary")
    workflow.set_finish_point("end")
    return workflow.compile()

def run_model_training(data_path: str, input_text: str, target_variable: str = None, 
                      problem_type: str = None, enable_manual_review: bool = False, 
                      enable_rag: bool = True) -> Dict[str, Any]:
    """
    è¿è¡Œæ¨¡å‹è®­ç»ƒçš„ä¸»å‡½æ•°
    
    Args:
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        input_text: ç”¨æˆ·è¾“å…¥çš„è®­ç»ƒéœ€æ±‚
        target_variable: ç›®æ ‡å˜é‡åç§°
        problem_type: é—®é¢˜ç±»å‹ ('classification', 'regression', 'clustering')
        enable_manual_review: æ˜¯å¦å¯ç”¨äººå·¥å®¡æ ¸
        enable_rag: æ˜¯å¦å¯ç”¨RAG
    
    Returns:
        åŒ…å«æ¨¡å‹è®­ç»ƒç»“æœçš„å­—å…¸
    """
    data = pd.read_csv(data_path)
    
    initial_state = ModelTrainingState(
        data=data,
        data_summary="",
        recommended_steps="",
        training_code="",
        model_results=None,
        error=None,
        retry_count=0,
        target_variable=target_variable or "",
        problem_type=problem_type or determine_problem_type(data, target_variable or ""),
        sample_test_passed=False  # æ–°å¢
    )
    
    graph = build_training_graph(
        user_instructions=input_text, 
        enable_manual_review=enable_manual_review, 
        enable_rag=enable_rag
    )
    
    print("\n=== æ¨¡å‹è®­ç»ƒå·¥ä½œæµå›¾ ===")
    graph.get_graph().print_ascii()
    
    final_state = graph.invoke(initial_state)
    
    if final_state["model_results"] is not None:
        print("\n=== æ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆ ===")
        # ä¿å­˜æ¨¡å‹ç»“æœ
        os.makedirs("output", exist_ok=True)
        import pickle
        with open("output/model_results.pkl", "wb") as f:
            pickle.dump(final_state["model_results"], f)
        print("æ¨¡å‹ç»“æœå·²ä¿å­˜åˆ° 'output/model_results.pkl'")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if "best_model" in final_state["model_results"]:
            with open("output/best_model.pkl", "wb") as f:
                pickle.dump(final_state["model_results"]["best_model"], f)
            print("æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° 'output/best_model.pkl'")
            
        return final_state["model_results"]
    else:
        print("æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return None

if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    data_path = "/Users/runkeruan/Desktop/RBM/data-agent-for-futures/output/engineered_cleaned_B.csv"
    input_text = "è¯·å¯¹è¿™ä»½æœŸè´§æ•°æ®è¿›è¡Œæœºå™¨å­¦ä¹ å»ºæ¨¡ï¼Œé¢„æµ‹ä»·æ ¼è¶‹åŠ¿æˆ–æ”¶ç›Šç‡"
    target_variable = None  # æ ¹æ®å®é™…æƒ…å†µè®¾ç½®ç›®æ ‡å˜é‡ï¼Œä¾‹å¦‚ "close_price" æˆ– "return"
    
    model_results = run_model_training(
        data_path=data_path,
        input_text=input_text,
        target_variable=target_variable,
        problem_type=None,  # è®©ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹
        enable_manual_review=False,
        enable_rag=False
    ) 